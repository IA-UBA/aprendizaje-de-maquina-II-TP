{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T13:58:52.626717Z",
     "start_time": "2024-03-23T13:58:51.434801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AWS_ACCESS_KEY_ID=minio\n",
      "env: AWS_SECRET_ACCESS_KEY=minio123\n",
      "env: MLFLOW_S3_ENDPOINT_URL=http://localhost:9000\n",
      "env: AWS_ENDPOINT_URL_S3=http://localhost:9000\n"
     ]
    }
   ],
   "source": [
    "import awswrangler as wr\n",
    "\n",
    "import mlflow\n",
    "\n",
    "# Para que funcione, todos nuestros scripts debemos exportar las siguientes variables de entorno\n",
    "%env AWS_ACCESS_KEY_ID=minio   \n",
    "%env AWS_SECRET_ACCESS_KEY=minio123 \n",
    "%env MLFLOW_S3_ENDPOINT_URL=http://localhost:9000\n",
    "%env AWS_ENDPOINT_URL_S3=http://localhost:9000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Búsqueda de mejor modelo e hiperparámetros\n",
    "\n",
    "Dado nuestro dataset, el cual ya pasó por el proceso de ETL y se encuentra en nuestro S3 bucket, vamos a realizar una búsqueda de cual seria el mejor modelo y que hiperparametros usar.\n",
    "\n",
    "La búsqueda de hiperparametros la haremos usando Optuna y el tracking será realizado mediante MLFlow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T13:58:52.633829Z",
     "start_time": "2024-03-23T13:58:52.629497Z"
    }
   },
   "outputs": [],
   "source": [
    "mlflow_server = \"http://localhost:5000\"\n",
    "\n",
    "mlflow.set_tracking_uri(mlflow_server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T13:58:53.919756Z",
     "start_time": "2024-03-23T13:58:53.345903Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cargamos los datos para realizar nuestro estudio.\n",
    "# OBS, no vamos a cargar los datos de testing, nada de Data leakage por aquí\n",
    "X_train =  wr.s3.read_csv(\"s3://data/final/train/water_X_train.csv\")\n",
    "y_train =  wr.s3.read_csv(\"s3://data/final/train/water_y_train.csv\")\n",
    "\n",
    "X_test =  wr.s3.read_csv(\"s3://data/final/test/water_X_test.csv\")\n",
    "y_test =  wr.s3.read_csv(\"s3://data/final/test/water_y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.800591</td>\n",
       "      <td>-1.510326</td>\n",
       "      <td>-0.274480</td>\n",
       "      <td>-1.398306</td>\n",
       "      <td>-0.384074</td>\n",
       "      <td>-0.145190</td>\n",
       "      <td>0.401201</td>\n",
       "      <td>1.127540</td>\n",
       "      <td>0.385070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.854370</td>\n",
       "      <td>-1.017271</td>\n",
       "      <td>1.466335</td>\n",
       "      <td>0.360593</td>\n",
       "      <td>-0.458307</td>\n",
       "      <td>-0.267888</td>\n",
       "      <td>-1.828221</td>\n",
       "      <td>0.076059</td>\n",
       "      <td>0.491950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.062761</td>\n",
       "      <td>-2.005646</td>\n",
       "      <td>-0.530256</td>\n",
       "      <td>-0.497127</td>\n",
       "      <td>-0.328010</td>\n",
       "      <td>1.216102</td>\n",
       "      <td>0.338255</td>\n",
       "      <td>0.562725</td>\n",
       "      <td>1.970750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.608615</td>\n",
       "      <td>-1.125973</td>\n",
       "      <td>-0.262820</td>\n",
       "      <td>1.843514</td>\n",
       "      <td>-0.654414</td>\n",
       "      <td>0.974800</td>\n",
       "      <td>0.784255</td>\n",
       "      <td>-1.525841</td>\n",
       "      <td>-0.215729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.196108</td>\n",
       "      <td>1.142426</td>\n",
       "      <td>-0.744293</td>\n",
       "      <td>0.456643</td>\n",
       "      <td>0.823439</td>\n",
       "      <td>-0.406695</td>\n",
       "      <td>0.290145</td>\n",
       "      <td>-0.103250</td>\n",
       "      <td>-0.731019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ph  Hardness    Solids  Chloramines   Sulfate  Conductivity  \\\n",
       "0 -0.800591 -1.510326 -0.274480    -1.398306 -0.384074     -0.145190   \n",
       "1  0.854370 -1.017271  1.466335     0.360593 -0.458307     -0.267888   \n",
       "2 -0.062761 -2.005646 -0.530256    -0.497127 -0.328010      1.216102   \n",
       "3 -0.608615 -1.125973 -0.262820     1.843514 -0.654414      0.974800   \n",
       "4  0.196108  1.142426 -0.744293     0.456643  0.823439     -0.406695   \n",
       "\n",
       "   Organic_carbon  Trihalomethanes  Turbidity  \n",
       "0        0.401201         1.127540   0.385070  \n",
       "1       -1.828221         0.076059   0.491950  \n",
       "2        0.338255         0.562725   1.970750  \n",
       "3        0.784255        -1.525841  -0.215729  \n",
       "4        0.290145        -0.103250  -0.731019  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlación de features con la variable objetivo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T13:58:55.742436Z",
     "start_time": "2024-03-23T13:58:54.704687Z"
    }
   },
   "outputs": [],
   "source": [
    "from plots import plot_correlation_with_target, plot_information_gain_with_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T13:58:55.925315Z",
     "start_time": "2024-03-23T13:58:55.743462Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dado que estamos usando como tracking a MLFlow, mostrar los gráficos aquí no tiene sentido.\n",
    "correlation_plot = plot_correlation_with_target(X_train, y_train, target_col=\"Potability\")\n",
    "information_gain_plot = plot_information_gain_with_target(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arrancamos a experimentar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T13:58:58.450741Z",
     "start_time": "2024-03-23T13:58:57.929114Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import optuna\n",
    "\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow_aux import get_or_create_experiment\n",
    "\n",
    "from optuna_aux import champion_callback, objective\n",
    "\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, make_scorer\n",
    "\n",
    "# Optuna es un poco verboso, dejamos que solo nos muestre logs de errores\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea el experimento en MLFLow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T13:58:59.020326Z",
     "start_time": "2024-03-23T13:58:58.984334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Creemos el experimento\n",
    "experiment_id = get_or_create_experiment(\"Water Quality\")\n",
    "print(experiment_id)\n",
    "\n",
    "run_name_parent = \"best_hyperparam_\"  + datetime.datetime.today().strftime('%Y/%m/%d-%H:%M:%S\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos Optuna\n",
    "\n",
    "Agregamos como metrica a considerar el accuracy, de hecho medimos el champion por el accuracy tambien solo que mantenemos el log del f1 score en el mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T13:43:38.917876Z",
     "start_time": "2024-03-23T13:43:06.961581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial trial 0 achieved value: 0.675621346844833\n",
      "Trial 6 achieved value: 0.6764351828854338 with  0.1203% improvement\n",
      "Trial 14 achieved value: 0.6768425148609938 with  0.0602% improvement\n",
      "Trial 21 achieved value: 0.6768425148609939 with  0.0000% improvement\n",
      "Trial 25 achieved value: 0.6784701869421953 with  0.2399% improvement\n",
      "Trial 26 achieved value: 0.681318199129038 with  0.4180% improvement\n",
      "Trial 27 achieved value: 0.6874281787624393 with  0.8888% improvement\n",
      "Trial 32 achieved value: 0.6894606990876426 with  0.2948% improvement\n",
      "Trial 86 achieved value: 0.6898696868842416 with  0.0593% improvement\n",
      "Trial 110 achieved value: 0.6906860066564006 with  0.1182% improvement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'water_quality_model_dev'.\n",
      "2024/04/28 21:20:03 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: water_quality_model_dev, version 1\n",
      "Created version '1' of model 'water_quality_model_dev'.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(experiment_id=experiment_id, run_name=run_name_parent, nested=True):\n",
    "    # Inicializamos el estudio de Optuna\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "    # Ejecutamos los trials de optimización de hiperparametros. Cada uno de estos trials se ejecuta con un run separado, pero \n",
    "    # está anidado al run padre.\n",
    "    # Notar la adición del `champion_callback` para controlar qué mensajes mostramos\n",
    "    # Para entender mejor esto ver la documentación de objective y champion_callback en optuna_aux\n",
    "    study.optimize(lambda trial: objective(trial, X_train, y_train, experiment_id), n_trials=250, callbacks=[champion_callback])\n",
    "\n",
    "    # Una vez que terminamos la búsqueda, guardamos los mejores parámetros en el run padre.\n",
    "    mlflow.log_params(study.best_params)\n",
    "    mlflow.log_metric(\"best_train_f1\", study.best_value)\n",
    "\n",
    "    mlflow.set_tags(\n",
    "        tags={\n",
    "            \"project\": \"Water Quality\",\n",
    "            \"optimizer_engine\": \"optuna\",\n",
    "            \"model_family\": \"sklearn\",\n",
    "            \"feature_set_version\": 1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Una vez que terminamos la búsqueda, nos quedamos con el mejor modelo y lo entrenamos\n",
    "    if study.best_params[\"classifier\"] == \"SVC_linear\":\n",
    "        model = SVC(C=study.best_params[\"svc_c\"], kernel='linear', gamma='scale')\n",
    "    elif study.best_params[\"classifier\"] == \"SVC_poly\":\n",
    "        model = SVC(C=study.best_params[\"svc_c\"], kernel='poly', \n",
    "                    gamma='scale', degree=study.best_params[\"svc_poly_degree\"])\n",
    "    elif study.best_params[\"classifier\"] == \"SVC_rbf\":\n",
    "        model = SVC(C=study.best_params[\"svc_c\"], kernel='rbf', gamma='scale')\n",
    "    elif study.best_params[\"classifier\"] == \"DecisionTreeClassifier\":\n",
    "        model = DecisionTreeClassifier(max_depth=study.best_params[\"tree_max_depth\"])\n",
    "    else:\n",
    "        model = RandomForestClassifier(max_depth=study.best_params[\"rf_max_depth\"], \n",
    "                                       n_estimators=study.best_params[\"rf_n_estimators\"])\n",
    "\n",
    "    model = model.fit(X_train, y_train.to_numpy().ravel())\n",
    "\n",
    "    # Y testeamos el modelo y logueamos el resultado\n",
    "    y_pred = model.predict(X_test)\n",
    "    f1_score = f1_score(y_test.to_numpy().ravel(), y_pred)\n",
    "    accuracy = accuracy_score(y_test.to_numpy().ravel(), y_pred)\n",
    "    mlflow.log_metric(\"test_f1\", f1_score)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    # Logueamos los artefactos de las gráficas de correlación y de information_gain\n",
    "    mlflow.log_figure(figure=correlation_plot, artifact_file=\"correlation_plot.png\")\n",
    "    mlflow.log_figure(figure=information_gain_plot, artifact_file=\"information_gain_plot.png\")\n",
    "\n",
    "    # Guardamos el artefacto del modelo\n",
    "    artifact_path = \"model\"\n",
    "\n",
    "    signature = infer_signature(X_train, model.predict(X_train))\n",
    "\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=artifact_path,\n",
    "        signature=signature,\n",
    "        serialization_format='cloudpickle',\n",
    "        registered_model_name=\"water_quality_model_dev\",\n",
    "        metadata={\"model_data_version\": 1}\n",
    "    )\n",
    "\n",
    "    # Obtenemos la ubicación del modelo guardado en MLFlow\n",
    "    model_uri = mlflow.get_artifact_uri(artifact_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testeando el modelo\n",
    "\n",
    "Una vez que el modelo fue entrenado, podemos levantarlo y testearlo de una forma agnóstica a donde está guardado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T13:52:48.990896Z",
     "start_time": "2024-03-23T13:52:48.840129Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 9/9 [00:00<00:00, 815.13it/s]\n"
     ]
    }
   ],
   "source": [
    "loaded = mlflow.sklearn.load_model(model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T13:52:52.816010Z",
     "start_time": "2024-03-23T13:52:52.805948Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\workspace\\aprendizaje-de-maquina-II-TP\\venv\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "test_data = [-1.41456982, -0.90755244, -0.26      ,  0.56886629,  2.52275163,\n",
    "       -0.91573277,  0.39324227,  0.13926734,  1.38534189]\n",
    "loaded.predict(np.array(test_data).reshape([1, -1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registramos el modelo \n",
    "\n",
    "Realizamos el registro del modelo en MLflow. En este registro se pone el modelo productivo que luego se usará para servir en formato on-line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T13:53:33.534969Z",
     "start_time": "2024-03-23T13:53:33.462363Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/28 21:20:03 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: water_quality_model_prod, version 1\n"
     ]
    }
   ],
   "source": [
    "from mlflow import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "name = \"water_quality_model_prod\"\n",
    "desc = \"This classifier predict water potability (1 = potable)\"\n",
    "\n",
    "# Creamos el modelo productivo\n",
    "client.create_registered_model(name=name, description=desc)\n",
    "\n",
    "# Guardamos como tag los hiper-parametros en la version del modelo\n",
    "tags = model.get_params()\n",
    "tags[\"model\"] = type(model).__name__\n",
    "tags[\"f1-score\"] = f1_score\n",
    "\n",
    "# Guardamos la version del modelo\n",
    "result = client.create_model_version(\n",
    "    name=name,\n",
    "    source=model_uri,\n",
    "    run_id=model_uri.split(\"/\")[-3],\n",
    "    tags=tags\n",
    ")\n",
    "\n",
    "# Y creamos como la version con el alias de champion para poder levantarlo en nuestro\n",
    "# proceso de servicio del modelo on-line.\n",
    "client.set_registered_model_alias(name, \"champion\", result.version)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
